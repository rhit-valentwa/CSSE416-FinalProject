{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56e7d0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CNN Data Visualizer\n",
      "============================================================\n",
      "Found 4 CNN data batches\n",
      "Found 4 buffer batches\n",
      "\n",
      "Processing 4 batches with complete data...\n",
      "\n",
      "Creating visualizations for batch_0000_ep0_step100 (Episode 0, Step 100)...\n",
      "  - Input frames...\n",
      "  - Conv1 activations...\n",
      "  - Conv2 activations...\n",
      "  - Conv3 activations...\n",
      "  - Q-values...\n",
      "  - Buffer comparison...\n",
      "✓ Completed batch_0000_ep0_step100\n",
      "Creating visualizations for batch_0001_ep0_step200 (Episode 0, Step 200)...\n",
      "  - Input frames...\n",
      "  - Conv1 activations...\n",
      "  - Conv2 activations...\n",
      "  - Conv3 activations...\n",
      "  - Q-values...\n",
      "  - Buffer comparison...\n",
      "✓ Completed batch_0001_ep0_step200\n",
      "Creating visualizations for batch_0002_ep0_step400 (Episode 0, Step 400)...\n",
      "  - Input frames...\n",
      "  - Conv1 activations...\n",
      "  - Conv2 activations...\n",
      "  - Conv3 activations...\n",
      "  - Q-values...\n",
      "  - Buffer comparison...\n",
      "✓ Completed batch_0002_ep0_step400\n",
      "Creating visualizations for batch_0003_ep0_step500 (Episode 0, Step 500)...\n",
      "  - Input frames...\n",
      "  - Conv1 activations...\n",
      "  - Conv2 activations...\n",
      "  - Conv3 activations...\n",
      "  - Q-values...\n",
      "  - Buffer comparison...\n",
      "✓ Completed batch_0003_ep0_step500\n",
      "\n",
      "============================================================\n",
      "All visualizations saved to: visualizations\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "# =============================\n",
    "# CONFIGURATION\n",
    "# =============================\n",
    "BUFFER_DIR = \"../cnn_analyze/game_frames\"\n",
    "CNN_DATA_DIR = \"../cnn_analyze/cnn_frames\"\n",
    "OUTPUT_DIR = \"visualizations\"\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# =============================\n",
    "# UTILITY FUNCTIONS\n",
    "# =============================\n",
    "def get_available_batches(directory):\n",
    "    \"\"\"Get list of all available batch directories\"\"\"\n",
    "    batches = [d for d in os.listdir(directory) \n",
    "               if os.path.isdir(os.path.join(directory, d)) and d.startswith('batch_')]\n",
    "    batches.sort(key=lambda x: int(x.split('_')[1]))\n",
    "    return batches\n",
    "\n",
    "def load_buffer_images(buffer_dir, batch_name, buffer_type):\n",
    "    \"\"\"Load all frames from a specific buffer type\"\"\"\n",
    "    buffer_path = os.path.join(buffer_dir, batch_name, buffer_type)\n",
    "    if not os.path.exists(buffer_path):\n",
    "        return None\n",
    "    \n",
    "    frames = []\n",
    "    frame_files = sorted([f for f in os.listdir(buffer_path) if f.endswith('.png')])\n",
    "    \n",
    "    for frame_file in frame_files:\n",
    "        img = Image.open(os.path.join(buffer_path, frame_file))\n",
    "        frames.append(np.array(img))\n",
    "    \n",
    "    return frames\n",
    "\n",
    "def load_cnn_data(cnn_dir, batch_name):\n",
    "    \"\"\"Load all CNN activation data for a batch\"\"\"\n",
    "    batch_path = os.path.join(cnn_dir, batch_name)\n",
    "    if not os.path.exists(batch_path):\n",
    "        return None\n",
    "    \n",
    "    data = {}\n",
    "    \n",
    "    # Load all .npy files\n",
    "    for file in os.listdir(batch_path):\n",
    "        if file.endswith('.npy'):\n",
    "            key = file.replace('.npy', '')\n",
    "            data[key] = np.load(os.path.join(batch_path, file), allow_pickle=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def normalize_for_display(array):\n",
    "    \"\"\"Normalize array to 0-255 range for display\"\"\"\n",
    "    arr_min, arr_max = array.min(), array.max()\n",
    "    if arr_max > arr_min:\n",
    "        return ((array - arr_min) / (arr_max - arr_min) * 255).astype(np.uint8)\n",
    "    else:\n",
    "        return (array * 255).astype(np.uint8)\n",
    "\n",
    "# =============================\n",
    "# VISUALIZATION FUNCTIONS\n",
    "# =============================\n",
    "def visualize_input_frames(input_data, save_path):\n",
    "    \"\"\"Visualize all 6 input frames\"\"\"\n",
    "    # input_data shape: (1, 6, H, W)\n",
    "    frames = input_data[0]  # Remove batch dimension\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    fig.suptitle('Input Frames to CNN (6 Sequential Frames)', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        frame = frames[i]\n",
    "        ax.imshow(frame, cmap='gray')\n",
    "        ax.set_title(f'Frame {i} (t-{5-i})', fontsize=12)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def visualize_conv_layer(activation, layer_name, save_path, max_filters=32):\n",
    "    \"\"\"Visualize feature maps from a convolutional layer\"\"\"\n",
    "    # activation shape: (1, num_filters, H, W)\n",
    "    feature_maps = activation[0]  # Remove batch dimension\n",
    "    num_filters = min(feature_maps.shape[0], max_filters)\n",
    "    \n",
    "    # Calculate grid size\n",
    "    grid_size = int(np.ceil(np.sqrt(num_filters)))\n",
    "    \n",
    "    fig, axes = plt.subplots(grid_size, grid_size, figsize=(20, 20))\n",
    "    fig.suptitle(f'{layer_name} - Feature Maps (showing {num_filters}/{feature_maps.shape[0]} filters)', \n",
    "                 fontsize=16, fontweight='bold')\n",
    "    \n",
    "    for i in range(grid_size * grid_size):\n",
    "        row = i // grid_size\n",
    "        col = i % grid_size\n",
    "        ax = axes[row, col] if grid_size > 1 else axes\n",
    "        \n",
    "        if i < num_filters:\n",
    "            feature_map = feature_maps[i]\n",
    "            normalized = normalize_for_display(feature_map)\n",
    "            ax.imshow(normalized, cmap='viridis')\n",
    "            ax.set_title(f'Filter {i}\\n[{feature_map.min():.2f}, {feature_map.max():.2f}]', \n",
    "                        fontsize=8)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def visualize_filter_statistics(activation, layer_name, save_path):\n",
    "    \"\"\"Visualize statistics of filter activations\"\"\"\n",
    "    # activation shape: (1, num_filters, H, W)\n",
    "    feature_maps = activation[0]  # Remove batch dimension\n",
    "    \n",
    "    # Calculate statistics for each filter\n",
    "    num_filters = feature_maps.shape[0]\n",
    "    means = [feature_maps[i].mean() for i in range(num_filters)]\n",
    "    stds = [feature_maps[i].std() for i in range(num_filters)]\n",
    "    maxs = [feature_maps[i].max() for i in range(num_filters)]\n",
    "    mins = [feature_maps[i].min() for i in range(num_filters)]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle(f'{layer_name} - Filter Statistics', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # Mean activations\n",
    "    axes[0, 0].bar(range(num_filters), means, color='blue', alpha=0.7)\n",
    "    axes[0, 0].set_title('Mean Activation per Filter')\n",
    "    axes[0, 0].set_xlabel('Filter Index')\n",
    "    axes[0, 0].set_ylabel('Mean Value')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Standard deviation\n",
    "    axes[0, 1].bar(range(num_filters), stds, color='green', alpha=0.7)\n",
    "    axes[0, 1].set_title('Standard Deviation per Filter')\n",
    "    axes[0, 1].set_xlabel('Filter Index')\n",
    "    axes[0, 1].set_ylabel('Std Dev')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Max activations\n",
    "    axes[1, 0].bar(range(num_filters), maxs, color='red', alpha=0.7)\n",
    "    axes[1, 0].set_title('Max Activation per Filter')\n",
    "    axes[1, 0].set_xlabel('Filter Index')\n",
    "    axes[1, 0].set_ylabel('Max Value')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Min activations\n",
    "    axes[1, 1].bar(range(num_filters), mins, color='orange', alpha=0.7)\n",
    "    axes[1, 1].set_title('Min Activation per Filter')\n",
    "    axes[1, 1].set_xlabel('Filter Index')\n",
    "    axes[1, 1].set_ylabel('Min Value')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def visualize_activation_heatmap(activation, layer_name, save_path, num_filters=16):\n",
    "    \"\"\"Create a heatmap showing activation patterns across filters\"\"\"\n",
    "    # activation shape: (1, num_filters, H, W)\n",
    "    feature_maps = activation[0]  # Remove batch dimension\n",
    "    num_to_show = min(num_filters, feature_maps.shape[0])\n",
    "    \n",
    "    # Flatten spatial dimensions and take subset of filters\n",
    "    data = feature_maps[:num_to_show].reshape(num_to_show, -1)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(20, 8))\n",
    "    sns.heatmap(data, cmap='viridis', ax=ax, cbar_kws={'label': 'Activation Value'})\n",
    "    ax.set_title(f'{layer_name} - Activation Heatmap (First {num_to_show} Filters)', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Spatial Position (flattened)')\n",
    "    ax.set_ylabel('Filter Index')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def visualize_q_values(q_values, action_taken, save_path):\n",
    "    \"\"\"Visualize Q-values as a bar chart\"\"\"\n",
    "    q_vals = q_values[0] if len(q_values.shape) > 1 else q_values\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    actions = np.arange(len(q_vals))\n",
    "    colors = ['red' if i == action_taken else 'blue' for i in actions]\n",
    "    \n",
    "    bars = ax.bar(actions, q_vals, color=colors, alpha=0.7, edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    # Highlight the chosen action\n",
    "    ax.axvline(action_taken, color='red', linestyle='--', linewidth=2, alpha=0.5, \n",
    "               label=f'Chosen Action: {action_taken}')\n",
    "    \n",
    "    ax.set_xlabel('Action Index', fontsize=12)\n",
    "    ax.set_ylabel('Q-Value', fontsize=12)\n",
    "    ax.set_title(f'Q-Values for All Actions\\n(Chosen: {action_taken}, Q={q_vals[action_taken]:.4f})', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    ax.set_xticks(actions)\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    ax.legend()\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, (bar, val) in enumerate(zip(bars, q_vals)):\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{val:.3f}',\n",
    "                ha='center', va='bottom' if val >= 0 else 'top', \n",
    "                fontsize=10, fontweight='bold' if i == action_taken else 'normal')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def visualize_buffer_comparison(buffer_frames_dict, save_path):\n",
    "    \"\"\"Compare all buffer types side by side\"\"\"\n",
    "    buffer_types = ['original', 'normalized', 'downscaled', 'grayscale']\n",
    "    \n",
    "    # Check which buffers are available\n",
    "    available_buffers = {k: v for k, v in buffer_frames_dict.items() if v is not None}\n",
    "    \n",
    "    if not available_buffers:\n",
    "        return\n",
    "    \n",
    "    # Get number of frames (assume all buffers have same number)\n",
    "    num_frames = len(list(available_buffers.values())[0])\n",
    "    num_buffer_types = len(available_buffers)\n",
    "    \n",
    "    fig, axes = plt.subplots(num_buffer_types, num_frames, \n",
    "                            figsize=(3*num_frames, 3*num_buffer_types))\n",
    "    fig.suptitle('Buffer Comparison Across Processing Steps', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    for i, (buffer_name, frames) in enumerate(available_buffers.items()):\n",
    "        for j, frame in enumerate(frames):\n",
    "            if num_buffer_types == 1:\n",
    "                ax = axes[j]\n",
    "            elif num_frames == 1:\n",
    "                ax = axes[i]\n",
    "            else:\n",
    "                ax = axes[i, j]\n",
    "            \n",
    "            ax.imshow(frame, cmap='gray' if len(frame.shape) == 2 else None)\n",
    "            if j == 0:\n",
    "                ax.set_ylabel(buffer_name.capitalize(), fontsize=10, fontweight='bold')\n",
    "            if i == 0:\n",
    "                ax.set_title(f'Frame {j}', fontsize=10)\n",
    "            ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def create_comprehensive_report(batch_name, cnn_data, buffer_frames, output_dir):\n",
    "    \"\"\"Create a comprehensive visualization report for a batch\"\"\"\n",
    "    batch_output_dir = os.path.join(output_dir, batch_name)\n",
    "    os.makedirs(batch_output_dir, exist_ok=True)\n",
    "    \n",
    "    # Load info\n",
    "    info = cnn_data.get('info', None)\n",
    "    if info is not None:\n",
    "        info = info.item() if isinstance(info, np.ndarray) else info\n",
    "        action_taken = info.get('action_taken', 0)\n",
    "        episode = info.get('episode', 0)\n",
    "        step = info.get('step', 0)\n",
    "    else:\n",
    "        action_taken = 0\n",
    "        episode = 0\n",
    "        step = 0\n",
    "    \n",
    "    print(f\"Creating visualizations for {batch_name} (Episode {episode}, Step {step})...\")\n",
    "    \n",
    "    # 1. Input frames\n",
    "    if 'input' in cnn_data:\n",
    "        print(\"  - Input frames...\")\n",
    "        visualize_input_frames(cnn_data['input'], \n",
    "                             os.path.join(batch_output_dir, '1_input_frames.png'))\n",
    "    \n",
    "    # 2. Conv1 layer\n",
    "    if 'conv1' in cnn_data:\n",
    "        print(\"  - Conv1 activations...\")\n",
    "        visualize_conv_layer(cnn_data['conv1'], 'Conv1 (32 filters, 8x8 kernel, stride 4)',\n",
    "                           os.path.join(batch_output_dir, '2_conv1_features.png'))\n",
    "        visualize_filter_statistics(cnn_data['conv1'], 'Conv1',\n",
    "                                  os.path.join(batch_output_dir, '2_conv1_statistics.png'))\n",
    "        visualize_activation_heatmap(cnn_data['conv1'], 'Conv1',\n",
    "                                   os.path.join(batch_output_dir, '2_conv1_heatmap.png'))\n",
    "    \n",
    "    # 3. Conv2 layer\n",
    "    if 'conv2' in cnn_data:\n",
    "        print(\"  - Conv2 activations...\")\n",
    "        visualize_conv_layer(cnn_data['conv2'], 'Conv2 (64 filters, 4x4 kernel, stride 2)',\n",
    "                           os.path.join(batch_output_dir, '3_conv2_features.png'))\n",
    "        visualize_filter_statistics(cnn_data['conv2'], 'Conv2',\n",
    "                                  os.path.join(batch_output_dir, '3_conv2_statistics.png'))\n",
    "        visualize_activation_heatmap(cnn_data['conv2'], 'Conv2',\n",
    "                                   os.path.join(batch_output_dir, '3_conv2_heatmap.png'))\n",
    "    \n",
    "    # 4. Conv3 layer\n",
    "    if 'conv3' in cnn_data:\n",
    "        print(\"  - Conv3 activations...\")\n",
    "        visualize_conv_layer(cnn_data['conv3'], 'Conv3 (64 filters, 3x3 kernel, stride 1)',\n",
    "                           os.path.join(batch_output_dir, '4_conv3_features.png'))\n",
    "        visualize_filter_statistics(cnn_data['conv3'], 'Conv3',\n",
    "                                  os.path.join(batch_output_dir, '4_conv3_statistics.png'))\n",
    "        visualize_activation_heatmap(cnn_data['conv3'], 'Conv3',\n",
    "                                   os.path.join(batch_output_dir, '4_conv3_heatmap.png'))\n",
    "    \n",
    "    # 5. Q-values\n",
    "    if 'q_values' in cnn_data:\n",
    "        print(\"  - Q-values...\")\n",
    "        visualize_q_values(cnn_data['q_values'], action_taken,\n",
    "                         os.path.join(batch_output_dir, '5_q_values.png'))\n",
    "    \n",
    "    # 6. Buffer comparison\n",
    "    if buffer_frames:\n",
    "        print(\"  - Buffer comparison...\")\n",
    "        visualize_buffer_comparison(buffer_frames,\n",
    "                                  os.path.join(batch_output_dir, '0_buffer_comparison.png'))\n",
    "    \n",
    "    print(f\"✓ Completed {batch_name}\")\n",
    "\n",
    "def visualize_all_batches():\n",
    "    \"\"\"Main function to visualize all available batches\"\"\"\n",
    "    # Get available batches\n",
    "    cnn_batches = get_available_batches(CNN_DATA_DIR)\n",
    "    buffer_batches = get_available_batches(BUFFER_DIR)\n",
    "    \n",
    "    print(f\"Found {len(cnn_batches)} CNN data batches\")\n",
    "    print(f\"Found {len(buffer_batches)} buffer batches\")\n",
    "    \n",
    "    # Find common batches\n",
    "    common_batches = set(cnn_batches) & set(buffer_batches)\n",
    "    print(f\"\\nProcessing {len(common_batches)} batches with complete data...\\n\")\n",
    "    \n",
    "    for batch in sorted(common_batches):\n",
    "        # Load CNN data\n",
    "        cnn_data = load_cnn_data(CNN_DATA_DIR, batch)\n",
    "        \n",
    "        # Load buffer data\n",
    "        buffer_frames = {\n",
    "            'original': load_buffer_images(BUFFER_DIR, batch, 'original'),\n",
    "            'normalized': load_buffer_images(BUFFER_DIR, batch, 'normalized'),\n",
    "            'downscaled': load_buffer_images(BUFFER_DIR, batch, 'downscaled'),\n",
    "            'grayscale': load_buffer_images(BUFFER_DIR, batch, 'grayscale')\n",
    "        }\n",
    "        \n",
    "        # Create visualizations\n",
    "        create_comprehensive_report(batch, cnn_data, buffer_frames, OUTPUT_DIR)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"All visualizations saved to: {OUTPUT_DIR}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "# =============================\n",
    "# MAIN EXECUTION\n",
    "# =============================\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\"*60)\n",
    "    print(\"CNN Data Visualizer\")\n",
    "    print(\"=\"*60)\n",
    "    visualize_all_batches()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "416",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
